# ğŸ† Academic Embedding Model Evaluator

**Author**: Cody Champion

## Current Model Leaderboard

Our sophisticated leaderboard system shows exactly how different AI models perform at understanding research papers:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                    ğŸ† Model Leaderboard                                         â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“        â”‚
â”‚ â”ƒ Model             â”ƒ Score â”ƒ Own Title-Abstract â”ƒ Same Field Separation â”ƒ Avg Std â”ƒ        â”‚
â”‚ â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©        â”‚
â”‚ â”‚ Bedrock          â”‚ 0.449 â”‚ 0.710              â”‚ 0.103                 â”‚ 0.118   â”‚        â”‚
â”‚ â”‚ MPNet            â”‚ 0.443 â”‚ 0.714              â”‚ 0.271                 â”‚ 0.134   â”‚        â”‚
â”‚ â”‚ MiniLM-L12       â”‚ 0.439 â”‚ 0.688              â”‚ 0.246                 â”‚ 0.130   â”‚        â”‚
â”‚ â”‚ MiniLM-L6        â”‚ 0.433 â”‚ 0.667              â”‚ 0.242                 â”‚ 0.129   â”‚        â”‚
â”‚ â”‚ RoBERTa-Large-ST â”‚ 0.410 â”‚ 0.601              â”‚ 0.165                 â”‚ 0.110   â”‚        â”‚
â”‚ â”‚ DistilRoBERTa    â”‚ 0.410 â”‚ 0.593              â”‚ 0.185                 â”‚ 0.120   â”‚        â”‚
â”‚ â”‚ MS-Marco         â”‚ 0.374 â”‚ 0.582              â”‚ 0.135                 â”‚ 0.126   â”‚        â”‚
â”‚ â”‚ S-BioBert        â”‚ 0.352 â”‚ 0.637              â”‚ 0.163                 â”‚ 0.118   â”‚        â”‚
â”‚ â”‚ Contriever       â”‚ 0.344 â”‚ 0.664              â”‚ 0.108                 â”‚ 0.082   â”‚        â”‚
â”‚ â”‚ Multi-MiniLM     â”‚ 0.343 â”‚ 0.495              â”‚ 0.135                 â”‚ 0.130   â”‚        â”‚
â”‚ â”‚ QA-MPNet         â”‚ 0.332 â”‚ 0.673              â”‚ 0.092                 â”‚ 0.078   â”‚        â”‚
â”‚ â”‚ BioBERT-NLI      â”‚ 0.302 â”‚ 0.608              â”‚ 0.097                 â”‚ 0.105   â”‚        â”‚
â”‚ â”‚ Specter          â”‚ 0.278 â”‚ 0.788              â”‚ 0.086                 â”‚ 0.072   â”‚        â”‚
â”‚ â”‚ GTE-Large        â”‚ 0.274 â”‚ 0.926              â”‚ 0.069                 â”‚ 0.038   â”‚        â”‚
â”‚ â”‚ GTE-Base         â”‚ 0.273 â”‚ 0.919              â”‚ 0.066                 â”‚ 0.038   â”‚        â”‚
â”‚ â”‚ BGE-Large        â”‚ 0.266 â”‚ 0.925              â”‚ 0.074                 â”‚ 0.036   â”‚        â”‚
â”‚ â”‚ E5-Large         â”‚ 0.265 â”‚ 0.890              â”‚ 0.052                 â”‚ 0.034   â”‚        â”‚
â”‚ â”‚ E5-Base          â”‚ 0.262 â”‚ 0.848              â”‚ 0.045                 â”‚ 0.036   â”‚        â”‚
â”‚ â”‚ BGE-Base         â”‚ 0.262 â”‚ 0.887              â”‚ 0.064                 â”‚ 0.034   â”‚        â”‚
â”‚ â”‚ SciBERT          â”‚ 0.256 â”‚ 0.714              â”‚ 0.049                 â”‚ 0.052   â”‚        â”‚
â”‚ â”‚ BERT-Base        â”‚ 0.249 â”‚ 0.779              â”‚ 0.056                 â”‚ 0.060   â”‚        â”‚
â”‚ â”‚ BiomedVLP        â”‚ 0.243 â”‚ 0.778              â”‚ 0.045                 â”‚ 0.051   â”‚        â”‚
â”‚ â”‚ DistilBERT       â”‚ 0.239 â”‚ 0.837              â”‚ 0.045                 â”‚ 0.046   â”‚        â”‚
â”‚ â”‚ BERT-Large       â”‚ 0.238 â”‚ 0.845              â”‚ 0.045                 â”‚ 0.046   â”‚        â”‚
â”‚ â”‚ BioLinkBERT      â”‚ 0.235 â”‚ 0.851              â”‚ 0.043                 â”‚ 0.041   â”‚        â”‚
â”‚ â”‚ BioBERT          â”‚ 0.223 â”‚ 0.886              â”‚ 0.025                 â”‚ 0.029   â”‚        â”‚
â”‚ â”‚ BiomedNLP        â”‚ 0.208 â”‚ 0.962              â”‚ 0.008                 â”‚ 0.011   â”‚        â”‚
â”‚ â”‚ RoBERTa-Base     â”‚ 0.208 â”‚ 0.926              â”‚ 0.007                 â”‚ 0.016   â”‚        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### Understanding the Metrics:
- **Score**: Overall performance score (higher is better)
- **Own Title-Abstract**: How well the model connects a paper's title with its content
- **Same Field Separation**: How accurately it distinguishes between related and unrelated papers
- **Avg Std**: Consistency of the model (lower means more reliable)

## ğŸ¯ Beautiful Real-Time Progress Tracking

Watch the analysis happen in real-time with our elegant console interface:

```
ğŸš€ Starting Academic Embedding Model Evaluation
ğŸ“š Loaded configuration from config/config.yaml
ğŸ¤– Models to evaluate: 24
ğŸ”¬ Research fields: 35
ğŸ“„ Papers per field: 50

Fetching papers...

ğŸ“Š Query statistics for artificial intelligence:
   - Papers found: 50
   - Papers checked: 50
   - Rejected (too short): 0
   - Rejected (too long): 0

ğŸ“Š Query statistics for machine learning:
   - Papers found: 50
   - Papers checked: 50
   - Rejected (too short): 0
   - Rejected (too long): 0

....

ğŸ“Š Paper Collection Summary:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Field                          â”ƒ Papers â”ƒ Avg Tokens â”ƒ Token Range â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ artificial intelligence        â”‚ 50     â”‚ 250.0      â”‚ 88-451      â”‚
â”‚ machine learning               â”‚ 50     â”‚ 254.9      â”‚ 73-472      â”‚
â”‚ computer vision                â”‚ 50     â”‚ 250.0      â”‚ 65-468      â”‚
â”‚ natural language processing    â”‚ 50     â”‚ 254.6      â”‚ 65-502      â”‚
â”‚ cybersecurity                  â”‚ 50     â”‚ 250.1      â”‚ 67-488      â”‚
â”‚ quantum computing              â”‚ 50     â”‚ 245.5      â”‚ 65-483      â”‚
â”‚ ....                           â”‚ ...    â”‚ ...        â”‚ ...         â”‚
â”‚ advanced manufacturing         â”‚ 50     â”‚ 254.0      â”‚ 76-502      â”‚
â”‚ biotechnology                  â”‚ 50     â”‚ 243.8      â”‚ 54-502      â”‚
â”‚ computational biology          â”‚ 50     â”‚ 249.6      â”‚ 65-468      â”‚
â”‚ quantum materials              â”‚ 50     â”‚ 238.8      â”‚ 54-502      â”‚
â”‚ sustainable energy             â”‚ 50     â”‚ 247.9      â”‚ 57-502      â”‚
â”‚ artificial intelligence ethics â”‚ 50     â”‚ 250.1      â”‚ 88-451      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Processed: BERT-Large
âœ… Processed: RoBERTa-Base
...

â ¦    Processing Models (15/24) - Est. 2.1h remaining â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  62%      
Getting title embeddings (50/1750)   â”â”â”â”â•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  11%      0:01:31   

Saving results...


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                ğŸ† Model Leaderboard                                                                                                                                        â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“                                                                                                        â”‚
â”‚ â”ƒ Model            â”ƒ Score â”ƒ Own Title-Abstract â”ƒ Same Field Separation â”ƒ Avg Std â”ƒ                                                                                                        â”‚
â”‚ â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©                                                                                                        â”‚
â”‚ â”‚ Bedrock          â”‚ 0.449 â”‚ 0.710              â”‚ 0.103                 â”‚ 0.118   â”‚                                                                                                        â”‚
â”‚ â”‚ MPNet            â”‚ 0.443 â”‚ 0.714              â”‚ 0.271                 â”‚ 0.134   â”‚                                                                                                        â”‚
â”‚ â”‚ MiniLM-L12       â”‚ 0.439 â”‚ 0.688              â”‚ 0.246                 â”‚ 0.130   â”‚                                                                                                        â”‚
â”‚ â”‚ MiniLM-L6        â”‚ 0.433 â”‚ 0.667              â”‚ 0.242                 â”‚ 0.129   â”‚                                                                                                        â”‚
â”‚ â”‚ ...              â”‚ ...   â”‚ ...                â”‚ ...                   â”‚ ...     â”‚
â”‚ â”‚ SciBERT          â”‚ 0.256 â”‚ 0.714              â”‚ 0.049                 â”‚ 0.052   â”‚                                                                                                        â”‚
â”‚ â”‚ BERT-Base        â”‚ 0.249 â”‚ 0.779              â”‚ 0.056                 â”‚ 0.060   â”‚                                                                                                        â”‚
â”‚ â”‚ BiomedVLP        â”‚ 0.243 â”‚ 0.778              â”‚ 0.045                 â”‚ 0.051   â”‚                                                                                                        â”‚
â”‚ â”‚ DistilBERT       â”‚ 0.239 â”‚ 0.837              â”‚ 0.045                 â”‚ 0.046   â”‚                                                                                                        â”‚
â”‚ â”‚ BERT-Large       â”‚ 0.238 â”‚ 0.845              â”‚ 0.045                 â”‚ 0.046   â”‚                                                                                                        â”‚
â”‚ â”‚ BioLinkBERT      â”‚ 0.235 â”‚ 0.851              â”‚ 0.043                 â”‚ 0.041   â”‚                                                                                                        â”‚
â”‚ â”‚ BioBERT          â”‚ 0.223 â”‚ 0.886              â”‚ 0.025                 â”‚ 0.029   â”‚                                                                                                        â”‚
â”‚ â”‚ BiomedNLP        â”‚ 0.208 â”‚ 0.962              â”‚ 0.008                 â”‚ 0.011   â”‚                                                                                                        â”‚
â”‚ â”‚ RoBERTa-Base     â”‚ 0.208 â”‚ 0.926              â”‚ 0.007                 â”‚ 0.016   â”‚                                                                                                        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ’¾ Leaderboard saved to: experiments\experiment_20241226_112605\model_leaderboard.csv

```

## ğŸ“Š Professional Experiment Tracking

Every experiment is automatically documented with detailed statistics and configurations:

### ğŸ“ˆ Collection Statistics
```yaml
# collection_statistics.yaml
date_range:
  earliest: '2024-03-18'
  latest: '2024-12-20'
papers_per_field:
  advanced manufacturing: 50
  artificial intelligence: 50
  artificial intelligence ethics: 50
  astronomical sciences: 50
  atmospheric science: 50
  bioinformatics: 50
  biomedical engineering: 50
  biotechnology: 50
  climate science: 50
  cognitive science: 50
  computational biology: 50
  computational social science: 50
  computer vision: 50
  condensed matter physics: 50
  cybersecurity: 50
  data science: 50
  environmental science: 50
  genomics: 50
  machine learning: 50
  materials chemistry: 50
  materials science: 50
  molecular biology: 50
  nanotechnology: 50
  natural language processing: 50
  neuroscience: 50
  particle physics: 50
  quantum computing: 50
  quantum information science: 50
  quantum materials: 50
  quantum physics: 50
  renewable energy: 50
  robotics: 50
  semiconductor physics: 50
  sustainable energy: 50
  synthetic biology: 50
token_statistics:
  max: 502
  mean: 250.04057142857144
  median: 246.0
  min: 53
  std: 76.35648136649283
total_papers: 1750

```

## ğŸš€ Key Features

- ğŸ“Š Comprehensive model evaluation across multiple academic fields
- ğŸ”„ Support for various embedding models (Hugging Face models supported)
- ğŸ“‘ Multiple comparison metrics
- ğŸ’¾ Efficient caching system
- ğŸ“ˆ Detailed performance leaderboard
- ğŸ¯ Beautiful progress tracking
- ğŸ“Š Professional experiment logging

## ğŸ”§ Hardware Acceleration & Cloud Integration

### ğŸ–¥ï¸ GPU Support (Optional)
Works efficiently on both CPU and GPU:
- Automatic hardware detection
- CPU-only setup works well for most cases
- Optional GPU acceleration for faster processing
- All models support both CPU and GPU execution

Requirements:
- Basic: Any modern CPU
- Optional GPU: CUDA-compatible GPU with PyTorch support

### â˜ï¸ AWS Bedrock Integration
Includes AWS Bedrock's Titan Embeddings model:
- State-of-the-art embedding quality
- Cloud-based processing
- No local compute requirements
- Production-ready capabilities

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone [repository-url]
cd embedding-benchmarking-arxiv
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up environment:
```bash
cp .env-example .env
# Add your HuggingFace token to .env
```

## âš™ï¸ Configuration

Create your config file with our comprehensive model selection (there are many more in the example yaml):

```yaml
models:
  # Cloud Provider Models
  'Bedrock': 'Bedrock'  # Amazon's Titan
  
  # Scientific/Academic Specialized
  'Specter': 'allenai/specter'
  'SciBERT': 'allenai/scibert_scivocab_uncased'
  'BioLinkBERT': 'michiyasunaga/BioLinkBERT-base'
  
  # Strong General Purpose Models
  'MPNet': 'sentence-transformers/all-mpnet-base-v2'
  'MiniLM': 'sentence-transformers/all-MiniLM-L6-v2'
  
  # E5 Family
  'E5-Base': 'intfloat/e5-base'
  'E5-Large': 'intfloat/e5-large'

fields:
  # Computer & Information Science
  - "artificial intelligence"
  - "machine learning"
  - "computer vision"
  
  # Biological Sciences
  - "molecular biology"
  - "neuroscience"
  - "genomics"
  
  # Physical Sciences
  - "quantum physics"
  - "materials science"
  - "astronomical sciences"
```

## ğŸš€ Usage

### Basic Usage
```bash
python -m src.embedding_benchmarking.cli evaluate
```

### Advanced Options
```bash
python -m src.embedding_benchmarking.cli evaluate \
  --cache-dir embedding_cache \
  --max-papers 100 \
  --config custom_config.yaml \
  --output-dir results
```

## ğŸ“Š Output Files

1. `embedding_comparison_results.csv`: Detailed metrics
2. `model_leaderboard.csv`: Aggregated performance scores
3. Experiment directory with:
   - Leaderboard and detailed metrics comparisons 
   - Full statistical analysis
   - Configuration snapshots
   - Paper metadata
   - Detailed logs


## Project Structure

```
.
â”œâ”€â”€ src/embedding_benchmarking/  # Main package source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                  # Command line interface
â”‚   â”œâ”€â”€ config.py               # Configuration handling
â”‚   â”œâ”€â”€ data.py                 # Data processing
â”‚   â”œâ”€â”€ embedding_evaluator.py  # Core evaluation logic
â”‚   â”œâ”€â”€ evaluation.py           # Evaluation metrics
â”‚   â”œâ”€â”€ models.py              # Model implementations
â”‚   â””â”€â”€ utils.py               # Utility functions
â”‚
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ config-example.yaml    # Example configuration
â”‚   â””â”€â”€ .env-example          # Environment variables example
â”‚
â”œâ”€â”€ experiments/               # Experiment results
â”‚   â””â”€â”€ experiment_20241219_111718/
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ license.md
â”‚
â””â”€â”€ requirements.txt          # Project dependencies
```



## ğŸ“š Citation

```bibtex
@software{embedding_benchmarking_arxiv,
  title = {Academic Embedding Model Evaluator},
  author = {Champion, Cody},
  year = {2024},
  description = {A tool for evaluating embedding models on academic paper similarity tasks}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

Ready to revolutionize your research paper analysis? Get started today! ğŸš€
